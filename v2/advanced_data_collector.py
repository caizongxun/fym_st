import pandas as pd
import numpy as np
import requests
import time
import io
import zipfile
from datetime import datetime
from typing import Dict, Optional
import os


# ============================================================
# Binance API æ­·å²æ•¸æ“šä¿ç•™æœŸé™åˆ¶ (ç„¡æ³•ç¹é)
# ------------------------------------------------------------
# funding_rate (fapi/v1/fundingRate):   å®Œæ•´æ­·å² (2019 è‡³ä»Š)
# open_interest (openInterestHist):     åƒ…æœ€è¿‘ 30 å¤©
# long_short_ratio (topLongShort...):   åƒ…æœ€è¿‘ 30 å¤©
# taker_buy_sell (takerlongshortRatio): åƒ…æœ€è¿‘ 30 å¤©
#
# å®Œæ•´æ­·å² OI ä¸‹è¼‰ä¾†æº:
# https://data.binance.vision/data/futures/um/monthly/openInterestFapi/
# ============================================================


class BinanceAdvancedDataCollector:

    def __init__(self):
        self.spot_base_url = 'https://api.binance.com'
        self.futures_base_url = 'https://fapi.binance.com'
        self.public_data_url = 'https://data.binance.vision'
        self.rate_limit_delay = 0.3

    def get_earliest_available_time(self, symbol: str) -> int:
        """å¾å°ç…§è¡¨å–å¾—å¹£ç¨®æœŸè²¨ä¸Šç·šæ—¥"""
        earliest_dates = {
            'BTCUSDT': '2019-09-08',
            'ETHUSDT': '2020-02-12',
            'BNBUSDT': '2020-04-09',
            'ADAUSDT': '2021-03-10',
            'SOLUSDT': '2021-08-11',
            'XRPUSDT': '2020-11-13',
            'DOTUSDT': '2021-01-14',
            'AVAXUSDT': '2021-11-24',
            'MATICUSDT': '2021-05-09',
            'LINKUSDT': '2021-01-14',
        }
        date_str = earliest_dates.get(symbol, '2021-01-01')
        return int(pd.to_datetime(date_str).timestamp() * 1000)

    def calculate_order_flow_from_taker_buysell(self, taker_df: pd.DataFrame) -> pd.DataFrame:
        if taker_df.empty:
            return pd.DataFrame()
        df = taker_df.copy()
        total_volume = df['buyVol'] + df['sellVol']
        df['delta_volume'] = df['buyVol'] - df['sellVol']
        df['buy_pressure'] = df['buyVol'] / total_volume
        df['sell_pressure'] = df['sellVol'] / total_volume
        df['cvd'] = df['delta_volume'].cumsum()
        df['taker_imbalance'] = df['delta_volume'] / total_volume
        df['cvd_change'] = df['cvd'].diff()
        df['cvd_change_rate'] = df['cvd'].pct_change()
        df['cvd_ma7'] = df['cvd'].rolling(7).mean()
        df['cvd_ma24'] = df['cvd'].rolling(24).mean()
        df['cvd_momentum'] = df['cvd'].diff(7)
        df.fillna(0, inplace=True)
        df.replace([np.inf, -np.inf], 0, inplace=True)
        return df

    # ----------------------------------------------------------
    # 1. è³‡é‡‘è²»ç‡ (å®Œæ•´æ­·å²) â€” ä½¿ç”¨ startTime å¾€å¾Œçˆ¬
    # ----------------------------------------------------------
    def get_funding_rate(self, symbol: str, start_time: int, limit: int = 1000) -> pd.DataFrame:
        url = f"{self.futures_base_url}/fapi/v1/fundingRate"
        all_funding = []
        current_start = start_time
        round_count = 0

        print(f"  çˆ¬å–è³‡é‡‘è²»ç‡å®Œæ•´æ­·å² (å¾ {pd.to_datetime(start_time, unit='ms').strftime('%Y-%m-%d')})...")

        try:
            while True:
                params = {'symbol': symbol, 'startTime': current_start, 'limit': limit}
                resp = requests.get(url, params=params, timeout=10)
                resp.raise_for_status()
                data = resp.json()
                if not data:
                    break
                all_funding.extend(data)
                round_count += 1
                if round_count % 5 == 0:
                    print(f"    å·²çˆ¬å– {len(all_funding):,} ç­†...")
                if len(data) < limit:
                    break
                current_start = data[-1]['fundingTime'] + 1
                time.sleep(self.rate_limit_delay)

            if not all_funding:
                return pd.DataFrame()

            df = pd.DataFrame(all_funding)
            df['timestamp'] = pd.to_datetime(df['fundingTime'], unit='ms')
            df['fundingRate'] = df['fundingRate'].astype(float)
            df = df[['timestamp', 'fundingRate']].sort_values('timestamp').reset_index(drop=True)
            df['funding_rate_ma8'] = df['fundingRate'].rolling(8).mean()
            df['funding_rate_ma24'] = df['fundingRate'].rolling(24).mean()
            df['funding_rate_std'] = df['fundingRate'].rolling(24).std()
            df['funding_rate_extreme'] = (abs(df['fundingRate']) > df['funding_rate_std'] * 2).astype(int)
            df.fillna(0, inplace=True)
            print(f"    âœ… å…± {len(df):,} ç­† (å¾ {df['timestamp'].min().strftime('%Y-%m-%d')} è‡³ {df['timestamp'].max().strftime('%Y-%m-%d')})")
            return df
        except Exception as e:
            print(f"  âš ï¸ è³‡é‡‘è²»ç‡ç„¡æ³•ç²å–: {e}")
            return pd.DataFrame()

    # ----------------------------------------------------------
    # 2. æœªå¹³å€‰é‡ (åƒ…æœ€è¿‘ 30 å¤©) â€” ä¸å‚³ startTime
    # ----------------------------------------------------------
    def get_open_interest(self, symbol: str, interval: str = '15m', limit: int = 500) -> pd.DataFrame:
        url = f"{self.futures_base_url}/futures/data/openInterestHist"
        all_oi = []
        print(f"  çˆ¬å–æœªå¹³å€‰é‡ (æ³¨æ„: Binance API åƒ…ä¿ç•™æœ€è¿‘ 30 å¤©)...")
        params = {'symbol': symbol, 'period': interval, 'limit': limit}
        try:
            while True:
                resp = requests.get(url, params=params, timeout=10)
                resp.raise_for_status()
                data = resp.json()
                if not data:
                    break
                if all_oi and data[-1]['timestamp'] <= all_oi[-1]['timestamp']:
                    break
                all_oi.extend(data)
                if len(data) < limit:
                    break
                earliest = data[0]['timestamp']
                params['endTime'] = earliest - 1
                params.pop('startTime', None)
                time.sleep(self.rate_limit_delay)
            if not all_oi:
                return pd.DataFrame()
            df = pd.DataFrame(all_oi)
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['sumOpenInterest'] = df['sumOpenInterest'].astype(float)
            df['sumOpenInterestValue'] = df['sumOpenInterestValue'].astype(float)
            df = df.sort_values('timestamp').reset_index(drop=True)
            df['oi_change'] = df['sumOpenInterest'].diff()
            df['oi_change_rate'] = df['oi_change'] / df['sumOpenInterest'].shift(1)
            df['oi_ma7'] = df['sumOpenInterest'].rolling(7).mean()
            df['oi_ma30'] = df['sumOpenInterest'].rolling(30).mean()
            df.fillna(0, inplace=True)
            print(f"    âœ… å…± {len(df):,} ç­† (å¾ {df['timestamp'].min().strftime('%Y-%m-%d')} è‡³ {df['timestamp'].max().strftime('%Y-%m-%d')})")
            print(f"    â„¹ï¸ Binance API ç¡¬æ€§ 30 å¤©é™åˆ¶ï¼Œé€™æ˜¯æœ€å¤§å¯ç”¨é‡")
            return df
        except Exception as e:
            print(f"  âš ï¸ æœªå¹³å€‰é‡ç„¡æ³•ç²å–: {e}")
            return pd.DataFrame()

    # ----------------------------------------------------------
    # 3. å¤šç©ºæ¯” (åƒ…æœ€è¿‘ 30 å¤©)
    # ----------------------------------------------------------
    def get_long_short_ratio(self, symbol: str, interval: str = '15m', limit: int = 500) -> pd.DataFrame:
        url = f"{self.futures_base_url}/futures/data/topLongShortAccountRatio"
        all_ratio = []
        print(f"  çˆ¬å–å¤šç©ºæ¯” (æ³¨æ„: Binance API åƒ…ä¿ç•™æœ€è¿‘ 30 å¤©)...")
        params = {'symbol': symbol, 'period': interval, 'limit': limit}
        try:
            while True:
                resp = requests.get(url, params=params, timeout=10)
                resp.raise_for_status()
                data = resp.json()
                if not data:
                    break
                if all_ratio and data[-1]['timestamp'] <= all_ratio[-1]['timestamp']:
                    break
                all_ratio.extend(data)
                if len(data) < limit:
                    break
                earliest = data[0]['timestamp']
                params['endTime'] = earliest - 1
                params.pop('startTime', None)
                time.sleep(self.rate_limit_delay)
            if not all_ratio:
                return pd.DataFrame()
            df = pd.DataFrame(all_ratio)
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['longShortRatio'] = df['longShortRatio'].astype(float)
            df['longAccount'] = df['longAccount'].astype(float)
            df['shortAccount'] = df['shortAccount'].astype(float)
            df = df.sort_values('timestamp').reset_index(drop=True)
            df['ls_ratio_ma7'] = df['longShortRatio'].rolling(7).mean()
            df['ls_ratio_extreme'] = ((df['longShortRatio'] > 2) | (df['longShortRatio'] < 0.5)).astype(int)
            df.fillna(0, inplace=True)
            print(f"    âœ… å…± {len(df):,} ç­† (å¾ {df['timestamp'].min().strftime('%Y-%m-%d')} è‡³ {df['timestamp'].max().strftime('%Y-%m-%d')})")
            print(f"    â„¹ï¸ Binance API ç¡¬æ€§ 30 å¤©é™åˆ¶ï¼Œé€™æ˜¯æœ€å¤§å¯ç”¨é‡")
            return df
        except Exception as e:
            print(f"  âš ï¸ å¤šç©ºæ¯”ç„¡æ³•ç²å–: {e}")
            return pd.DataFrame()

    # ----------------------------------------------------------
    # 4. ä¸»å‹•è²·è³£æ¯” (åƒ…æœ€è¿‘ 30 å¤©)
    # ----------------------------------------------------------
    def get_taker_buy_sell(self, symbol: str, interval: str = '15m', limit: int = 500) -> pd.DataFrame:
        url = f"{self.futures_base_url}/futures/data/takerlongshortRatio"
        all_taker = []
        print(f"  çˆ¬å–ä¸»å‹•è²·è³£æ¯” (æ³¨æ„: Binance API åƒ…ä¿ç•™æœ€è¿‘ 30 å¤©)...")
        params = {'symbol': symbol, 'period': interval, 'limit': limit}
        try:
            while True:
                resp = requests.get(url, params=params, timeout=10)
                resp.raise_for_status()
                data = resp.json()
                if not data:
                    break
                if all_taker and data[-1]['timestamp'] <= all_taker[-1]['timestamp']:
                    break
                all_taker.extend(data)
                if len(data) < limit:
                    break
                earliest = data[0]['timestamp']
                params['endTime'] = earliest - 1
                params.pop('startTime', None)
                time.sleep(self.rate_limit_delay)
            if not all_taker:
                return pd.DataFrame()
            df = pd.DataFrame(all_taker)
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['buySellRatio'] = df['buySellRatio'].astype(float)
            df['buyVol'] = df['buyVol'].astype(float)
            df['sellVol'] = df['sellVol'].astype(float)
            df = df.sort_values('timestamp').reset_index(drop=True)
            df['taker_buy_sell_delta'] = df['buyVol'] - df['sellVol']
            df['taker_imbalance'] = df['taker_buy_sell_delta'] / (df['buyVol'] + df['sellVol'])
            df.fillna(0, inplace=True)
            print(f"    âœ… å…± {len(df):,} ç­† (å¾ {df['timestamp'].min().strftime('%Y-%m-%d')} è‡³ {df['timestamp'].max().strftime('%Y-%m-%d')})")
            print(f"    â„¹ï¸ Binance API ç¡¬æ€§ 30 å¤©é™åˆ¶ï¼Œé€™æ˜¯æœ€å¤§å¯ç”¨é‡")
            return df
        except Exception as e:
            print(f"  âš ï¸ ä¸»å‹•è²·è³£æ¯”ç„¡æ³•ç²å–: {e}")
            return pd.DataFrame()

    # ----------------------------------------------------------
    # 5. Binance Public Data â€” å®Œæ•´æ­·å² OI ä¸‹è¼‰
    # ----------------------------------------------------------
    def download_oi_from_public_data(
        self,
        symbol: str,
        output_dir: str = 'v2/advanced_data'
    ) -> pd.DataFrame:
        """
        å¾ data.binance.vision ä¸‹è¼‰å®Œæ•´æ­·å² OI (CSV zip æŒ‰æœˆ)
        URL: {base}/{symbol}/{symbol}-openInterest-{YYYY}-{MM}.zip

        è³‡æ–™æ ¼å¼: create_time, symbol, sum_open_interest, sum_open_interest_value
        """
        base_url = f"{self.public_data_url}/data/futures/um/monthly/openInterestFapi"
        start_time = self.get_earliest_available_time(symbol)
        start_date = pd.to_datetime(start_time, unit='ms').replace(day=1)
        end_date = datetime.now()

        print(f"\n  å¾ Binance Public Data ä¸‹è¼‰å®Œæ•´æ­·å² OI ({symbol})...")
        print(f"  æ™‚é–“ç¯„åœ: {start_date.strftime('%Y-%m')} è‡³ {end_date.strftime('%Y-%m')}")

        all_dfs = []
        current = start_date

        while current <= end_date:
            year = current.year
            month = current.month
            url = f"{base_url}/{symbol}/{symbol}-openInterest-{year}-{month:02d}.zip"

            try:
                resp = requests.get(url, timeout=30)
                if resp.status_code == 404:
                    print(f"    {year}-{month:02d}: ç„¡æ•¸æ“š (404)")
                    current = current + pd.DateOffset(months=1)
                    continue
                resp.raise_for_status()

                with zipfile.ZipFile(io.BytesIO(resp.content)) as z:
                    csv_name = z.namelist()[0]
                    with z.open(csv_name) as f:
                        try:
                            df_month = pd.read_csv(f)
                            # å˜—è©¦æ¨™æº–æ¬„ä½å
                            if 'create_time' not in df_month.columns:
                                f.seek(0)
                                df_month = pd.read_csv(
                                    f, header=None,
                                    names=['create_time', 'symbol', 'sum_open_interest', 'sum_open_interest_value']
                                )
                        except Exception:
                            df_month = pd.read_csv(
                                io.BytesIO(z.read(csv_name)), header=None,
                                names=['create_time', 'symbol', 'sum_open_interest', 'sum_open_interest_value']
                            )

                all_dfs.append(df_month)
                print(f"    âœ… {year}-{month:02d}: {len(df_month):,} ç­†")

            except Exception as e:
                print(f"    âš ï¸ {year}-{month:02d}: {str(e)[:50]}")

            current = current + pd.DateOffset(months=1)
            time.sleep(0.2)

        if not all_dfs:
            print(f"  âš ï¸ ç„¡æ³•ä¸‹è¼‰ä»»ä½• OI æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²çµ¡æˆ– URL å½¢å¼")
            return pd.DataFrame()

        df = pd.concat(all_dfs, ignore_index=True)

        # æ¨™æº–åŒ–æ¬„ä½å
        col_map = {
            'create_time': 'raw_time',
            'sum_open_interest': 'sumOpenInterest',
            'sum_open_interest_value': 'sumOpenInterestValue'
        }
        df = df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})

        # æ™‚é–“è§£æ (ms æˆ– datetime å­—ä¸²)
        if 'raw_time' in df.columns:
            try:
                df['timestamp'] = pd.to_datetime(df['raw_time'], unit='ms')
            except Exception:
                df['timestamp'] = pd.to_datetime(df['raw_time'])

        if 'timestamp' not in df.columns:
            print("  âš ï¸ ç„¡æ³•è§£ææ™‚é–“æ¬„ä½")
            return pd.DataFrame()

        df['sumOpenInterest'] = pd.to_numeric(df['sumOpenInterest'], errors='coerce')
        df['sumOpenInterestValue'] = pd.to_numeric(df.get('sumOpenInterestValue', 0), errors='coerce')
        df = df[['timestamp', 'sumOpenInterest', 'sumOpenInterestValue']]
        df = df.sort_values('timestamp').drop_duplicates('timestamp').reset_index(drop=True)

        # è¡ç”Ÿç‰¹å¾µ
        df['oi_change'] = df['sumOpenInterest'].diff()
        df['oi_change_rate'] = df['oi_change'] / df['sumOpenInterest'].shift(1)
        df['oi_ma7'] = df['sumOpenInterest'].rolling(7).mean()
        df['oi_ma30'] = df['sumOpenInterest'].rolling(30).mean()
        df.fillna(0, inplace=True)

        # å„²å­˜
        os.makedirs(output_dir, exist_ok=True)
        filepath = os.path.join(output_dir, f"{symbol}_open_interest_full.parquet")
        df.to_parquet(filepath, index=False)
        print(f"\n  âœ… å®Œæ•´æ­·å² OI å®Œæˆ")
        print(f"  å…± {len(df):,} ç­† (å¾ {df['timestamp'].min().strftime('%Y-%m-%d')} è‡³ {df['timestamp'].max().strftime('%Y-%m-%d')})")
        print(f"  ğŸ’¾ å„²å­˜: {filepath}")

        return df

    # ----------------------------------------------------------
    # æ”¶é›†æ‰€æœ‰ç‰¹å¾µ
    # ----------------------------------------------------------
    def collect_all_advanced_features(
        self,
        symbol: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        timeframe: str = '15m'
    ) -> Dict[str, pd.DataFrame]:

        start_time = self.get_earliest_available_time(symbol)
        if start_date:
            start_time = int(pd.to_datetime(start_date).timestamp() * 1000)
        start_label = pd.to_datetime(start_time, unit='ms').strftime('%Y-%m-%d')
        end_label = end_date or datetime.now().strftime('%Y-%m-%d')

        print(f"\n{'='*60}")
        print(f"æ”¶é›† {symbol} é€²éšç‰¹å¾µ")
        print(f"è³‡é‡‘è²»ç‡: {start_label} è‡³ {end_label} (å®Œæ•´æ­·å²)")
        print(f"OI/å¤šç©ºæ¯”/Taker: æœ€è¿‘ 30 å¤© (Binance API ç¡¬æ€§é™åˆ¶)")
        print(f"{'='*60}")

        results = {}

        print("\n[1/5] è³‡é‡‘è²»ç‡ (Funding Rate) â€” å®Œæ•´æ­·å²...")
        results['funding_rate'] = self.get_funding_rate(symbol, start_time)

        print("\n[2/5] æœªå¹³å€‰é‡ (Open Interest) â€” æœ€è¿‘ 30 å¤©...")
        results['open_interest'] = self.get_open_interest(symbol, timeframe)

        print("\n[3/5] å¤šç©ºæ¯” (Long/Short Ratio) â€” æœ€è¿‘ 30 å¤©...")
        results['long_short_ratio'] = self.get_long_short_ratio(symbol, timeframe)

        print("\n[4/5] ä¸»å‹•è²·è³£æ¯” (Taker Buy/Sell) â€” æœ€è¿‘ 30 å¤©...")
        taker_df = self.get_taker_buy_sell(symbol, timeframe)
        results['taker_buy_sell'] = taker_df

        print("\n[5/5] è¨‚å–®æµ CVD (å¾ Taker è¨ˆç®—)...")
        if not taker_df.empty:
            results['order_flow'] = self.calculate_order_flow_from_taker_buysell(taker_df)
            print(f"  âœ… ç”Ÿæˆ {len(results['order_flow']):,} ç­† CVD ç‰¹å¾µ")
        else:
            results['order_flow'] = pd.DataFrame()

        total = sum(len(v) for v in results.values() if not v.empty)
        print(f"\n{'='*60}")
        print(f"âœ… {symbol} æ”¶é›†å®Œæˆ, å…± {total:,} ç­†")
        print(f"{'='*60}\n")

        return results

    def save_advanced_features(
        self,
        symbol: str,
        features_dict: Dict[str, pd.DataFrame],
        output_dir: str = 'v2/advanced_data'
    ):
        os.makedirs(output_dir, exist_ok=True)
        for feature_type, df in features_dict.items():
            if df.empty:
                continue
            filepath = os.path.join(output_dir, f"{symbol}_{feature_type}.parquet")
            df.to_parquet(filepath, index=False)
            print(f"  ğŸ’¾ å„²å­˜: {filepath} ({len(df):,} ç­†)")


class BatchAdvancedDataCollector:
    def __init__(self):
        self.collector = BinanceAdvancedDataCollector()
        self.hf_symbols = [
            'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT',
            'ADAUSDT', 'AVAXUSDT', 'DOTUSDT', 'MATICUSDT', 'LINKUSDT',
            'UNIUSDT', 'LTCUSDT', 'ETCUSDT', 'XLMUSDT', 'ATOMUSDT',
            'FILUSDT', 'NEARUSDT', 'ALGOUSDT', 'VETUSDT', 'ICPUSDT',
            'APTUSDT', 'ARBUSDT', 'OPUSDT', 'INJUSDT', 'SUIUSDT',
            'PEPEUSDT', 'WIFUSDT', 'SHIBUSDT', 'DOGEUSDT', 'TRXUSDT',
            'TONUSDT', 'HBARUSDT', 'RENDERUSDT', 'FTMUSDT', 'AAVEUSDT',
            'RUNEUSDT', 'IMXUSDT', 'LDOUSDT'
        ]

    def download_all_oi_history(self, output_dir: str = 'v2/advanced_data'):
        """å¾ Binance Public Data ä¸‹è¼‰æ‰€æœ‰å¹£ç¨®å®Œæ•´æ­·å² OI"""
        print(f"\n{'='*80}")
        print(f"ä¸‹è¼‰å®Œæ•´æ­·å² OI (data.binance.vision)")
        print(f"å¹£ç¨®æ•¸é‡: {len(self.hf_symbols)}")
        print(f"{'='*80}")

        results = []
        for idx, symbol in enumerate(self.hf_symbols, 1):
            print(f"\n[{idx}/{len(self.hf_symbols)}] {symbol}")
            df = self.collector.download_oi_from_public_data(symbol, output_dir)
            results.append({'symbol': symbol, 'records': len(df), 'status': 'ok' if not df.empty else 'empty'})
            time.sleep(1)

        summary = pd.DataFrame(results)
        print("\næ‘˜è¦:")
        print(summary.to_string())
        return summary

    def collect_all_symbols(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        timeframe: str = '15m',
        output_dir: str = 'v2/advanced_data'
    ):
        os.makedirs(output_dir, exist_ok=True)
        summary = []

        for idx, symbol in enumerate(self.hf_symbols, 1):
            print(f"\n[{idx}/{len(self.hf_symbols)}] {symbol}")
            try:
                features_dict = self.collector.collect_all_advanced_features(
                    symbol=symbol, start_date=start_date,
                    end_date=end_date, timeframe=timeframe
                )
                self.collector.save_advanced_features(
                    symbol=symbol, features_dict=features_dict, output_dir=output_dir
                )
                summary.append({
                    'symbol': symbol,
                    'funding_rate': len(features_dict.get('funding_rate', pd.DataFrame())),
                    'open_interest': len(features_dict.get('open_interest', pd.DataFrame())),
                    'long_short_ratio': len(features_dict.get('long_short_ratio', pd.DataFrame())),
                    'taker_buy_sell': len(features_dict.get('taker_buy_sell', pd.DataFrame())),
                    'order_flow_cvd': len(features_dict.get('order_flow', pd.DataFrame())),
                    'status': 'success'
                })
                time.sleep(2)
            except Exception as e:
                print(f"  âŒ éŒ¯èª¤: {e}")
                summary.append({
                    'symbol': symbol, 'funding_rate': 0, 'open_interest': 0,
                    'long_short_ratio': 0, 'taker_buy_sell': 0, 'order_flow_cvd': 0,
                    'status': f'failed: {str(e)[:40]}'
                })

        summary_df = pd.DataFrame(summary)
        summary_df.to_csv(os.path.join(output_dir, 'collection_summary.csv'), index=False)
        print(summary_df.to_string())
        return summary_df


if __name__ == '__main__':
    BatchAdvancedDataCollector().collect_all_symbols(
        start_date=None, end_date=None,
        timeframe='15m', output_dir='v2/advanced_data'
    )
