import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
import sys
import glob
import time

from data_loader import CryptoDataLoader
from feature_engineering import FeatureEngineer
from label_generation import LabelGenerator
from pipeline import TradingPipeline
from model_trainer import ModelTrainer, TrendFilterTrainer
from inference_engine import InferenceEngine
from advanced_data_collector import BatchAdvancedDataCollector, BinanceAdvancedDataCollector
from advanced_feature_merger import AdvancedFeatureMerger


st.set_page_config(
    page_title="V2 äº¤æ˜“ç³»çµ±",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("V2 æ¨¡å¡ŠåŒ–äº¤æ˜“ç³»çµ±")

if 'data_loader' not in st.session_state:
    st.session_state.data_loader = CryptoDataLoader()

if 'pipeline' not in st.session_state:
    st.session_state.pipeline = TradingPipeline()

if 'batch_collector' not in st.session_state:
    st.session_state.batch_collector = BatchAdvancedDataCollector()

if 'feature_merger' not in st.session_state:
    st.session_state.feature_merger = AdvancedFeatureMerger()

tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "ğŸ“Š [1] æ•¸æ“šè¼‰å…¥",
    "ğŸ”„ [2] è³‡é‡‘è²»ç‡æ”¶é›†",
    "ğŸ› ï¸ [3] ç‰¹å¾µå·¥ç¨‹",
    "ğŸ·ï¸ [4] æ¨™ç±¤ç”Ÿæˆ",
    "ğŸ¤– [5] æ¨¡å‹è¨“ç·´",
    "ğŸ¯ [6] æ¨è«–æ¸¬è©¦",
    "â˜ï¸ [7] HF ä¸Šå‚³"
])

# ============================================================
# Tab 1: æ•¸æ“šè¼‰å…¥
# ============================================================
with tab1:
    st.header("æ•¸æ“šè¼‰å…¥")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("è³‡æ–™é›†è³‡è¨Š")
        info = st.session_state.data_loader.get_dataset_info()
        st.metric("äº¤æ˜“å°æ•¸é‡", info['total_symbols'])
        st.metric("æ™‚é–“æ¡†æ¶", len(info['timeframes']))
        st.metric("ç¸½æª”æ¡ˆæ•¸", info['total_files'])
        
        with st.expander("æŸ¥çœ‹æ‰€æœ‰äº¤æ˜“å°"):
            for symbol in info['symbols']:
                st.text(symbol)
    
    with col2:
        st.subheader("è¼‰å…¥æ•¸æ“š")
        
        col2_1, col2_2, col2_3 = st.columns(3)
        
        with col2_1:
            symbol = st.selectbox(
                "é¸æ“‡äº¤æ˜“å°",
                info['symbols'],
                key='load_symbol'
            )
        
        with col2_2:
            timeframe = st.selectbox(
                "é¸æ“‡æ™‚é–“æ¡†æ¶",
                info['timeframes'],
                key='load_timeframe'
            )
        
        with col2_3:
            st.write("")
            st.write("")
            if st.button("è¼‰å…¥æ•¸æ“š", use_container_width=True):
                with st.spinner('è¼‰å…¥ä¸­...'):
                    try:
                        df = st.session_state.data_loader.load_klines(symbol, timeframe)
                        df_prepared = st.session_state.data_loader.prepare_dataframe(df)
                        st.session_state.df_raw = df_prepared
                        st.session_state.current_symbol = symbol
                        st.session_state.current_timeframe = timeframe
                        st.success(f"æˆåŠŸè¼‰å…¥ {len(df_prepared)} ç­†æ•¸æ“š")
                    except Exception as e:
                        st.error(f"è¼‰å…¥å¤±æ•—: {str(e)}")
        
        if 'df_raw' in st.session_state:
            st.subheader("æ•¸æ“šé è¦½")
            df_display = st.session_state.df_raw.copy()
            st.dataframe(df_display.head(100), use_container_width=True, height=300)
            
            st.subheader("æ•¸æ“šçµ±è¨ˆ")
            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            with col_stat1:
                st.metric("ç¸½ç­†æ•¸", len(df_display))
            with col_stat2:
                st.metric("èµ·å§‹æ™‚é–“", df_display['timestamp'].min().strftime('%Y-%m-%d'))
            with col_stat3:
                st.metric("çµæŸæ™‚é–“", df_display['timestamp'].max().strftime('%Y-%m-%d'))
            with col_stat4:
                st.metric("å¹³å‡åƒ¹æ ¼", f"{df_display['close'].mean():.2f}")

# ============================================================
# Tab 2: è³‡é‡‘è²»ç‡æ”¶é›†
# ============================================================
with tab2:
    st.header("ğŸ”„ è³‡é‡‘è²»ç‡æ”¶é›†")
    
    st.info(
        "ğŸ’° **è³‡é‡‘è²»ç‡ (Funding Rate)**\n"
        "- Binance æœŸè²¨æ¯ 8 å°æ™‚ä¸€ç­†ï¼Œå…·å‚™ 2019ï½ä»Šå®Œæ•´æ­·å²\n"
        "- æ˜¯å”¯ä¸€å¯ç”¨äºè¨“ç·´çš„é€²éšç‰¹å¾µ (å…¶ä»–çš†åƒ… 30 å¤©)\n"
        "- æ”¶é›†å®Œæˆå¾Œåœ¨ [7] HF ä¸Šå‚³å±•é å°‡å…¶å‚™ä»½åˆ° HuggingFace"
    )
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("æ”¶é›†åƒæ•¸")
        
        collection_mode = st.radio(
            "æ”¶é›†æ¨¡å¼",
            ["å–®ä¸€å¹£ç¨®", f"æ‰¹é‡æ”¶é›† ({len(st.session_state.batch_collector.hf_symbols)}å€‹)"],
            key='collection_mode'
        )
        
        if collection_mode == "å–®ä¸€å¹£ç¨®":
            symbols_to_collect = [st.selectbox(
                "é¸æ“‡å¹£ç¨®",
                st.session_state.batch_collector.hf_symbols,
                key='adv_symbol'
            )]
        else:
            symbols_to_collect = st.session_state.batch_collector.hf_symbols
            with st.expander(f"æŸ¥çœ‹å¹£ç¨®æ¸…å–® ({len(symbols_to_collect)}å€‹)"):
                for sym in symbols_to_collect:
                    st.text(sym)
        
        output_dir = st.text_input(
            "è¼¸å‡ºç›®éŒ„",
            value='v2/advanced_data',
            key='adv_output_dir'
        )
        
        st.write("---")
        
        if st.button("ğŸš€ é–‹å§‹æ”¶é›†è³‡é‡‘è²»ç‡", use_container_width=True, type="primary"):
            st.session_state.collection_started = True
            st.rerun()
    
    with col2:
        if st.session_state.get('collection_started', False):
            st.subheader("æ”¶é›†é€²åº¦")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            summary_data = []
            
            collector = BinanceAdvancedDataCollector()
            os.makedirs(output_dir, exist_ok=True)
            
            for idx, symbol in enumerate(symbols_to_collect):
                progress = (idx + 1) / len(symbols_to_collect)
                progress_bar.progress(progress)
                status_text.text(f"æ­£åœ¨è™•ç† {symbol} ({idx+1}/{len(symbols_to_collect)})...")
                
                try:
                    start_time = collector.get_earliest_available_time(symbol)
                    df = collector.get_funding_rate(symbol, start_time)
                    
                    if not df.empty:
                        filepath = os.path.join(output_dir, f"{symbol}_funding_rate.parquet")
                        df.to_parquet(filepath, index=False)
                        summary_data.append({
                            'å¹£ç¨®': symbol,
                            'ç­†æ•¸': f"{len(df):,}",
                            'èµ·å§‹': df['timestamp'].min().strftime('%Y-%m-%d'),
                            'çµæŸ': df['timestamp'].max().strftime('%Y-%m-%d'),
                            'ç‹€æ…‹': 'âœ… æˆåŠŸ'
                        })
                    else:
                        summary_data.append({
                            'å¹£ç¨®': symbol, 'ç­†æ•¸': '0',
                            'èµ·å§‹': '-', 'çµæŸ': '-', 'ç‹€æ…‹': 'âš ï¸ ç„¡æ•¸æ“š'
                        })
                    
                    time.sleep(0.5)
                    
                except Exception as e:
                    summary_data.append({
                        'å¹£ç¨®': symbol, 'ç­†æ•¸': '0',
                        'èµ·å§‹': '-', 'çµæŸ': '-',
                        'ç‹€æ…‹': f'âŒ {str(e)[:20]}'
                    })
            
            progress_bar.progress(1.0)
            status_text.text("âœ… æ”¶é›†å®Œæˆ!")
            st.session_state.collection_summary = pd.DataFrame(summary_data)
            st.session_state.collection_started = False
            st.rerun()
        
        if 'collection_summary' in st.session_state:
            st.subheader("ğŸ“‹ æ”¶é›†æ‘˜è¦")
            st.dataframe(
                st.session_state.collection_summary,
                use_container_width=True,
                hide_index=True,
                height=400
            )
            
            df_sum = st.session_state.collection_summary
            success = (df_sum['ç‹€æ…‹'] == 'âœ… æˆåŠŸ').sum()
            
            col_m1, col_m2 = st.columns(2)
            with col_m1:
                st.metric("æˆåŠŸæ”¶é›†", f"{success}/{len(df_sum)}")
            with col_m2:
                st.metric("å¯ä¸Šå‚³æª”æ¡ˆ", f"{success} å€‹ .parquet")
            
            st.info("ğŸ’¡ æ”¶é›†å®Œæˆå¾Œï¼Œå‰å¾€ [7] HF ä¸Šå‚³å±•é é€²è¡Œå‚™ä»½")

# ============================================================
# Tab 3: ç‰¹å¾µå·¥ç¨‹
# ============================================================
with tab3:
    st.header("ç‰¹å¾µå·¥ç¨‹")
    
    if 'df_raw' not in st.session_state:
        st.warning("âš ï¸ è«‹å…ˆåœ¨ [1]æ•¸æ“šè¼‰å…¥ é é¢è¼‰å…¥æ•¸æ“š")
    else:
        col1, col2 = st.columns([1, 3])
        
        with col1:
            st.subheader("åƒæ•¸è¨­å®š")
            
            bb_period  = st.number_input("å¸ƒæ—å¸¶é€±æœŸ", 5, 50, 20)
            bb_std     = st.number_input("æ¨™æº–å·®å€æ•¸", 1.0, 3.0, 2.0, 0.1)
            lookback   = st.number_input("å›æº¯é€±æœŸ", 50, 200, 100)
            pivot_left = st.number_input("æ¨ç´å·¦å´Kç·š", 1, 10, 3)
            pivot_right= st.number_input("æ¨ç´å³å´Kç·š", 1, 10, 3)
            
            st.write("---")
            
            merge_advanced = st.checkbox(
                "ğŸ”¥ åˆä½µè³‡é‡‘è²»ç‡ç‰¹å¾µ",
                value=False,
                help="è‡ªå‹•è¼‰å…¥ funding_rate.parquet"
            )
            
            if st.button("è¨ˆç®—ç‰¹å¾µ", use_container_width=True):
                with st.spinner('è¨ˆç®—ä¸­...'):
                    try:
                        fe = FeatureEngineer(
                            bb_period=bb_period,
                            bb_std=bb_std,
                            lookback=lookback,
                            pivot_left=pivot_left,
                            pivot_right=pivot_right
                        )
                        st.session_state.df_features = fe.process_features(st.session_state.df_raw)
                        st.session_state.feature_engineer = fe
                        
                        base_features = len(fe.get_feature_columns())
                        
                        if merge_advanced:
                            if 'current_symbol' in st.session_state:
                                merger = st.session_state.feature_merger
                                st.session_state.df_features = merger.merge_for_training(
                                    st.session_state.df_features,
                                    st.session_state.current_symbol
                                )
                                adv_features = merger.get_training_feature_columns(st.session_state.df_features)
                                st.success(f"âœ… ç‰¹å¾µè¨ˆç®—å®Œæˆ: {len(st.session_state.df_features)} ç­† | åŸºç¤: {base_features} | è³‡é‡‘è²»ç‡: {len(adv_features)}")
                            else:
                                st.warning("âš ï¸ è«‹å…ˆè¼‰å…¥æ•¸æ“š")
                                st.success(f"âœ… åŸºç¤ç‰¹å¾µè¨ˆç®—å®Œæˆ: {len(st.session_state.df_features)} ç­† | ç‰¹å¾µæ•¸: {base_features}")
                        else:
                            st.success(f"âœ… åŸºç¤ç‰¹å¾µè¨ˆç®—å®Œæˆ: {len(st.session_state.df_features)} ç­† | ç‰¹å¾µæ•¸: {base_features}")
                    except Exception as e:
                        st.error(f"âŒ è¨ˆç®—å¤±æ•—: {str(e)}")
        
        with col2:
            if 'df_features' in st.session_state:
                st.subheader("ç‰¹å¾µæ•¸æ“šé è¦½")
                
                feature_cols = st.session_state.feature_engineer.get_feature_columns()
                adv_features = []
                if 'feature_merger' in st.session_state:
                    adv_features = st.session_state.feature_merger.get_training_feature_columns(
                        st.session_state.df_features
                    )
                
                all_features = feature_cols + adv_features
                display_cols = ['timestamp', 'close'] + all_features[:8]
                available_cols = [c for c in display_cols if c in st.session_state.df_features.columns]
                
                st.dataframe(
                    st.session_state.df_features[available_cols].head(50),
                    use_container_width=True,
                    height=300
                )
                
                st.subheader("ğŸ“Š ç‰¹å¾µåˆ—è¡¨")
                col_feat1, col_feat2 = st.columns(2)
                with col_feat1:
                    st.write("**åŸºç¤ç‰¹å¾µ**")
                    for feat in feature_cols:
                        st.text(f"â€¢ {feat}")
                with col_feat2:
                    if adv_features:
                        st.write(f"**è³‡é‡‘è²»ç‡ç‰¹å¾µ ({len(adv_features)}å€‹)**")
                        for feat in adv_features:
                            st.text(f"â€¢ {feat}")
                    else:
                        st.info("æœªè¼‰å…¥è³‡é‡‘è²»ç‡ç‰¹å¾µ")

# ============================================================
# Tab 4: æ¨™ç±¤ç”Ÿæˆ
# ============================================================
with tab4:
    st.header("æ¨™ç±¤ç”Ÿæˆ")
    
    if 'df_features' not in st.session_state:
        st.warning("âš ï¸ è«‹å…ˆåœ¨ [3]ç‰¹å¾µå·¥ç¨‹ é é¢è¨ˆç®—ç‰¹å¾µ")
    else:
        col1, col2 = st.columns([1, 3])
        
        with col1:
            st.subheader("åƒæ•¸è¨­å®š")
            
            atr_period = st.number_input("ATRé€±æœŸ", 5, 30, 14)
            sl_mult    = st.number_input("åœæATRå€æ•¸", 0.5, 3.0, 1.5, 0.1)
            tp_mult    = st.number_input("åœåˆ©ATRå€æ•¸", 1.0, 5.0, 3.0, 0.1)
            lookahead  = st.number_input("å‰ç¥Kç·šæ•¸", 5, 50, 16)
            
            if st.button("ç”Ÿæˆæ¨™ç±¤", use_container_width=True):
                with st.spinner('ç”Ÿæˆä¸­...'):
                    try:
                        lg = LabelGenerator(
                            atr_period=atr_period,
                            sl_atr_mult=sl_mult,
                            tp_atr_mult=tp_mult,
                            lookahead_bars=lookahead
                        )
                        st.session_state.df_labeled = lg.generate_labels(st.session_state.df_features)
                        st.session_state.label_generator = lg
                        stats = lg.get_label_statistics(st.session_state.df_labeled)
                        st.session_state.label_stats = stats
                        st.success("âœ… æ¨™ç±¤ç”Ÿæˆå®Œæˆ")
                    except Exception as e:
                        st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {str(e)}")
        
        with col2:
            if 'df_labeled' in st.session_state:
                st.subheader("æ¨™ç±¤çµ±è¨ˆ")
                stats = st.session_state.label_stats
                
                col_stat1, col_stat2 = st.columns(2)
                with col_stat1:
                    st.write("**åšå¤šæ¨£æœ¬**")
                    if 'long_total' in stats:
                        st.metric("ç¸½æ•¸", stats['long_total'])
                        st.metric("æˆåŠŸ", stats['long_success'])
                        st.metric("å¤±æ•—", stats['long_fail'])
                        st.metric("æˆåŠŸç‡", f"{stats['long_success_rate']:.2f}%")
                    else:
                        st.info("ç„¡åšå¤šæ¨£æœ¬")
                with col_stat2:
                    st.write("**åšç©ºæ¨£æœ¬**")
                    if 'short_total' in stats:
                        st.metric("ç¸½æ•¸", stats['short_total'])
                        st.metric("æˆåŠŸ", stats['short_success'])
                        st.metric("å¤±æ•—", stats['short_fail'])
                        st.metric("æˆåŠŸç‡", f"{stats['short_success_rate']:.2f}%")
                    else:
                        st.info("ç„¡åšç©ºæ¨£æœ¬")
                
                st.subheader("æ¨™ç±¤æ•¸æ“šé è¦½")
                display_cols = ['timestamp', 'close', 'lower', 'upper', 'atr',
                               'is_touching_lower', 'is_touching_upper',
                               'target_long', 'target_short']
                available_cols = [col for col in display_cols if col in st.session_state.df_labeled.columns]
                st.dataframe(
                    st.session_state.df_labeled[available_cols].head(50),
                    use_container_width=True,
                    height=300
                )

# ============================================================
# Tab 5: æ¨¡å‹è¨“ç·´
# ============================================================
with tab5:
    st.header("æ¨¡å‹è¨“ç·´")
    
    if 'df_labeled' not in st.session_state:
        st.warning("âš ï¸ è«‹å…ˆåœ¨ [4]æ¨™ç±¤ç”Ÿæˆ é é¢ç”Ÿæˆæ¨™ç±¤")
    else:
        col1, col2 = st.columns([1, 3])
        
        with col1:
            st.subheader("è¨“ç·´åƒæ•¸")
            
            direction    = st.selectbox("æ–¹å‘", ['long', 'short'])
            n_estimators = st.number_input("æ¨¹æ•¸é‡", 100, 1000, 300, 50)
            learning_rate= st.number_input("å­¸ç¿’ç‡", 0.001, 0.1, 0.01, 0.001, format="%.3f")
            max_depth    = st.number_input("æœ€å¤§æ·±åº¦", 3, 15, 4)
            train_ratio  = st.number_input("è¨“ç·´é›†æ¯”ä¾‹", 0.5, 0.9, 0.8, 0.05)
            
            st.write("---")
            col_btn1, col_btn2 = st.columns(2)
            
            with col_btn1:
                if st.button("è¨“ç·´åå½ˆæ¨¡å‹", use_container_width=True):
                    with st.spinner('è¨“ç·´ä¸­...'):
                        try:
                            df_train = st.session_state.label_generator.prepare_training_data(
                                st.session_state.df_labeled, direction=direction)
                            trainer = ModelTrainer(
                                model_type='bounce',
                                n_estimators=n_estimators,
                                learning_rate=learning_rate,
                                max_depth=max_depth
                            )
                            results = trainer.train(df_train, train_ratio=train_ratio)
                            os.makedirs('v2/models', exist_ok=True)
                            trainer.save_model(f'v2/models/bounce_{direction}_model.pkl')
                            st.session_state.bounce_results = results
                            st.success("âœ… åå½ˆæ¨¡å‹è¨“ç·´å®Œæˆ")
                        except Exception as e:
                            st.error(f"âŒ è¨“ç·´å¤±æ•—: {str(e)}")
            
            with col_btn2:
                if st.button("è¨“ç·´éæ¿¾æ¨¡å‹", use_container_width=True):
                    with st.spinner('è¨“ç·´ä¸­...'):
                        try:
                            df_train = st.session_state.label_generator.prepare_training_data(
                                st.session_state.df_labeled, direction=direction)
                            trainer = TrendFilterTrainer(
                                n_estimators=n_estimators,
                                learning_rate=learning_rate,
                                max_depth=max_depth
                            )
                            results = trainer.train(df_train, train_ratio=train_ratio)
                            os.makedirs('v2/models', exist_ok=True)
                            trainer.save_model(f'v2/models/filter_{direction}_model.pkl')
                            st.session_state.filter_results = results
                            st.success("âœ… éæ¿¾æ¨¡å‹è¨“ç·´å®Œæˆ")
                        except Exception as e:
                            st.error(f"âŒ è¨“ç·´å¤±æ•—: {str(e)}")
        
        with col2:
            st.subheader("è¨“ç·´çµæœ")
            col_res1, col_res2 = st.columns(2)
            
            with col_res1:
                st.write("**åå½ˆæ¨¡å‹**")
                if 'bounce_results' in st.session_state:
                    r = st.session_state.bounce_results
                    st.metric("è¨“ç·´ AUC", f"{r['train_auc']:.4f}")
                    st.metric("æ¸¬è©¦ AUC", f"{r['test_auc']:.4f}")
                    st.metric("è¨“ç·´æ¨£æœ¬", r['train_samples'])
                    st.metric("æ¸¬è©¦æ¨£æœ¬", r['test_samples'])
                    st.write("**ç‰¹å¾µé‡è¦æ€§ Top 10**")
                    st.dataframe(r['feature_importance'].head(10),
                                 use_container_width=True, hide_index=True, height=300)
                else:
                    st.info("å°šæœªè¨“ç·´")
            
            with col_res2:
                st.write("**éæ¿¾æ¨¡å‹**")
                if 'filter_results' in st.session_state:
                    r = st.session_state.filter_results
                    st.metric("è¨“ç·´ AUC", f"{r['train_auc']:.4f}")
                    st.metric("æ¸¬è©¦ AUC", f"{r['test_auc']:.4f}")
                    st.metric("è¨“ç·´æ¨£æœ¬", r['train_samples'])
                    st.metric("æ¸¬è©¦æ¨£æœ¬", r['test_samples'])
                    st.write("**ç‰¹å¾µé‡è¦æ€§ Top 10**")
                    st.dataframe(r['feature_importance'].head(10),
                                 use_container_width=True, hide_index=True, height=300)
                else:
                    st.info("å°šæœªè¨“ç·´")

# ============================================================
# Tab 6: æ¨è«–æ¸¬è©¦
# ============================================================
with tab6:
    st.header("æ¨è«–æ¸¬è©¦")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("æ¨¡å‹é¸æ“‡")
        direction_infer = st.selectbox("æ–¹å‘", ['long', 'short'], key='infer_direction')
        
        bounce_path = f'v2/models/bounce_{direction_infer}_model.pkl'
        filter_path = f'v2/models/filter_{direction_infer}_model.pkl'
        
        if os.path.exists(bounce_path) and os.path.exists(filter_path):
            st.success("âœ… æ¨¡å‹æª”æ¡ˆå­˜åœ¨")
            
            st.subheader("é–¾å€¤è¨­å®š")
            bounce_threshold = st.slider("åå½ˆé–¾å€¤", 0.0, 1.0, 0.65, 0.05)
            filter_threshold = st.slider("éæ¿¾é–¾å€¤", 0.0, 1.0, 0.40, 0.05)
            
            if st.button("åŸ·è¡Œæ¨è«–", use_container_width=True):
                if 'df_labeled' not in st.session_state:
                    st.error("âŒ è«‹å…ˆç”Ÿæˆæ¨™ç±¤æ•¸æ“š")
                else:
                    with st.spinner('æ¨è«–ä¸­...'):
                        try:
                            engine = InferenceEngine(
                                bounce_model_path=bounce_path,
                                filter_model_path=filter_path,
                                bounce_threshold=bounce_threshold,
                                filter_threshold=filter_threshold
                            )
                            df_test = st.session_state.label_generator.prepare_training_data(
                                st.session_state.df_labeled, direction=direction_infer)
                            df_predictions = engine.predict_batch(df_test)
                            stats = engine.get_statistics(df_predictions)
                            st.session_state.df_predictions = df_predictions
                            st.session_state.inference_stats = stats
                            st.success("âœ… æ¨è«–å®Œæˆ")
                        except Exception as e:
                            st.error(f"âŒ æ¨è«–å¤±æ•—: {str(e)}")
        else:
            st.error("âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
            st.info("è«‹å…ˆåœ¨ [5]æ¨¡å‹è¨“ç·´ é é¢è¨“ç·´æ¨¡å‹")
    
    with col2:
        if 'inference_stats' in st.session_state:
            st.subheader("æ¨è«–çµ±è¨ˆ")
            stats = st.session_state.inference_stats
            col_s1, col_s2, col_s3, col_s4 = st.columns(4)
            with col_s1: st.metric("ç¸½æ¨£æœ¬", stats['total_samples'])
            with col_s2: st.metric("æ ¸å‡†é€²å ´", stats['entry_approved'])
            with col_s3: st.metric("é€²å ´ç‡", f"{stats['entry_rate']:.2f}%")
            with col_s4:
                if 'approved_success_rate' in stats:
                    st.metric("æ ¸å‡†å¾ŒæˆåŠŸç‡", f"{stats['approved_success_rate']:.2f}%")
            
            st.subheader("æ¨è«–çµæœé è¦½")
            display_cols = ['timestamp', 'close', 'p_bounce', 'p_filter', 'signal', 'reason', 'target']
            available_cols = [col for col in display_cols if col in st.session_state.df_predictions.columns]
            st.dataframe(
                st.session_state.df_predictions[available_cols].head(50),
                use_container_width=True, height=300
            )
        else:
            st.info("è«‹å…ˆåŸ·è¡Œæ¨è«–")

# ============================================================
# Tab 7: HF ä¸Šå‚³
# ============================================================
with tab7:
    st.header("â˜ï¸ HuggingFace ä¸Šå‚³")
    
    st.info(
        "ğŸ“‚ **ä¸Šå‚³çµæ§‹**\n"
        "```\n"
        "klines/\n"
        "â”œâ”€â”€ BTCUSDT/\n"
        "â”‚   â”œâ”€â”€ [Kç·šæª”æ¡ˆ]  â† å·²åœ¨ HF\n"
        "â”‚   â””â”€â”€ BTCUSDT_funding_rate.parquet  â† æœ¬æ¬¡ä¸Šå‚³\n"
        "â”œâ”€â”€ ETHUSDT/\n"
        "â”‚   â””â”€â”€ ETHUSDT_funding_rate.parquet\n"
        "...\n"
        "```"
    )
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("ä¸Šå‚³è¨­å®š")
        
        hf_token = st.text_input(
            "HuggingFace Token",
            type="password",
            help="å¾ https://huggingface.co/settings/tokens ç²å–",
            key='hf_token'
        )
        
        hf_repo = st.text_input(
            "Repository ID",
            value="zongowo111/v2-crypto-ohlcv-data",
            key='hf_repo'
        )
        
        data_dir = st.text_input(
            "è³‡é‡‘è²»ç‡ç›®éŒ„",
            value="v2/advanced_data",
            key='hf_data_dir'
        )
        
        commit_msg = st.text_input(
            "Commit è¨Šæ¯",
            value=f"Add funding rate data - {datetime.now().strftime('%Y-%m-%d')}",
            key='hf_commit_msg'
        )
        
        st.write("---")
        st.caption("âš ï¸ ä½¿ç”¨å–®æ¬¡ commit æ•´åŒ…ä¸Šå‚³ï¼Œé å°‘ API é€Ÿç‡é™åˆ¶")
        
        if st.button("ğŸš€ ä¸€éµä¸Šå‚³åˆ° HuggingFace", use_container_width=True, type="primary"):
            if not hf_token:
                st.error("âŒ è«‹è¼¸å…¥ HuggingFace Token")
            elif not os.path.exists(data_dir):
                st.error(f"âŒ ç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
            else:
                with st.spinner('æº–å‚™ä¸Šå‚³...'):
                    try:
                        from huggingface_hub import HfApi, CommitOperationAdd
                        
                        api = HfApi(token=hf_token)
                        
                        # æ‰¾å‡ºæ‰€æœ‰ funding_rate.parquet
                        parquet_files = glob.glob(os.path.join(data_dir, "*_funding_rate.parquet"))
                        
                        if not parquet_files:
                            st.error(f"âŒ åœ¨ {data_dir} æ‰¾ä¸åˆ° *_funding_rate.parquet æª”æ¡ˆ")
                            st.info("è«‹å…ˆåœ¨ [2] è³‡é‡‘è²»ç‡æ”¶é›† å±•é åŸ·è¡Œæ”¶é›†")
                        else:
                            # æº–å‚™æ‰¹æ¬¡ä¸Šå‚³æ“ä½œ (CommitOperationAdd)
                            operations = []
                            file_map = []
                            
                            for fp in sorted(parquet_files):
                                filename = os.path.basename(fp)
                                # BTCUSDT_funding_rate.parquet -> BTCUSDT
                                symbol = filename.replace('_funding_rate.parquet', '')
                                path_in_repo = f"klines/{symbol}/{filename}"
                                operations.append(
                                    CommitOperationAdd(
                                        path_in_repo=path_in_repo,
                                        path_or_fileobj=fp
                                    )
                                )
                                file_map.append({'symbol': symbol, 'path': path_in_repo})
                            
                            st.write(f"ğŸ“ æº–å‚™ä¸Šå‚³ **{len(operations)}** å€‹æª”æ¡ˆ...")
                            
                            # å–®æ¬¡ commit æ•´åŒ…ä¸Šå‚³
                            result = api.create_commit(
                                repo_id=hf_repo,
                                repo_type="dataset",
                                operations=operations,
                                commit_message=commit_msg
                            )
                            
                            st.session_state.upload_result = {
                                'files': file_map,
                                'commit_url': result.commit_url
                            }
                            
                            st.success(f"âœ… æˆåŠŸä¸Šå‚³ {len(operations)} å€‹æª”æ¡ˆ")
                            st.markdown(f"**Commit URL:** [{result.commit_url}]({result.commit_url})")
                    
                    except ImportError:
                        st.error("âŒ è«‹å…ˆå®‰è£: pip install huggingface_hub")
                    except Exception as e:
                        st.error(f"âŒ ä¸Šå‚³å¤±æ•—: {str(e)}")
    
    with col2:
        st.subheader("ğŸ“ æ£€æŸ¥æœ¬åœ°æª”æ¡ˆ")
        
        data_dir_check = st.text_input(
            "ç›®éŒ„è·¯å¾‘",
            value="v2/advanced_data",
            key='data_dir_check'
        )
        
        if os.path.exists(data_dir_check):
            parquet_files = glob.glob(os.path.join(data_dir_check, "*_funding_rate.parquet"))
            
            st.metric("funding_rate.parquet æª”æ¡ˆæ•¸", len(parquet_files))
            
            if parquet_files:
                file_info = []
                total_size = 0
                for f in sorted(parquet_files):
                    size_mb = os.path.getsize(f) / (1024 * 1024)
                    total_size += size_mb
                    symbol = os.path.basename(f).replace('_funding_rate.parquet', '')
                    # å˜—è©¦è®€å–ç­†æ•¸
                    try:
                        df_preview = pd.read_parquet(f, columns=['timestamp'])
                        records = len(df_preview)
                        t_min = pd.read_parquet(f, columns=['timestamp'])['timestamp'].min().strftime('%Y-%m-%d')
                        t_max = pd.read_parquet(f, columns=['timestamp'])['timestamp'].max().strftime('%Y-%m-%d')
                    except Exception:
                        records = '?'
                        t_min = t_max = '-'
                    
                    file_info.append({
                        'å¹£ç¨®': symbol,
                        'ç­†æ•¸': f"{records:,}" if isinstance(records, int) else records,
                        'èµ·å§‹': t_min,
                        'çµæŸ': t_max,
                        'å¤§å° (MB)': f"{size_mb:.2f}"
                    })
                
                st.dataframe(
                    pd.DataFrame(file_info),
                    use_container_width=True,
                    hide_index=True,
                    height=400
                )
                st.metric("ç¸½å¤§å° (MB)", f"{total_size:.2f}")
        else:
            st.warning(f"âš ï¸ ç›®éŒ„ä¸å­˜åœ¨: {data_dir_check}")
        
        if 'upload_result' in st.session_state:
            st.subheader("ğŸ“‹ ä¸Šå‚³è¨˜éŒ„")
            r = st.session_state.upload_result
            st.write(f"å·²ä¸Šå‚³ {len(r['files'])} å€‹æª”æ¡ˆ")
            st.markdown(f"[Commit é€£çµ]({r['commit_url']})")
            df_uploaded = pd.DataFrame(r['files'])
            st.dataframe(df_uploaded, use_container_width=True, hide_index=True)

# ============================================================
# Sidebar
# ============================================================
st.sidebar.header("é—œæ–¼")
st.sidebar.info(
    """
    **V2 æ¨¡å¡ŠåŒ–äº¤æ˜“ç³»çµ±**
    
    åŠŸèƒ½æ¨¡å¡Š:
    - ğŸ“Š æ•¸æ“šè¼‰å…¥ (HuggingFace)
    - ğŸ”„ è³‡é‡‘è²»ç‡æ”¶é›† (Binance API)
    - ğŸ› ï¸ ç‰¹å¾µå·¥ç¨‹ (BB + SMC + POC + FVG)
    - ğŸ·ï¸ æ¨™ç±¤ç”Ÿæˆ (ATR å‹•æ…‹)
    - ğŸ¤– æ¨¡å‹è¨“ç·´ (LightGBM é˜²éæ“¬åˆ)
    - ğŸ¯ æ¨è«–æ¸¬è©¦ (å…±æŒ¯-å¦æ±º)
    - â˜ï¸ HF ä¸Šå‚³ (æ•´åŒ… commit)
    
    ç‰ˆæœ¬: 2.2.0
    """
)

st.sidebar.header("å¿«é€Ÿæ“ä½œ")
if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰ç·©å­˜"):
    for key in list(st.session_state.keys()):
        if key not in ['data_loader', 'pipeline', 'batch_collector', 'feature_merger']:
            del st.session_state[key]
    st.sidebar.success("âœ… ç·©å­˜å·²æ¸…é™¤")
    st.rerun()
