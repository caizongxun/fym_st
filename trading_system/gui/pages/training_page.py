import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
from datetime import datetime

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from core import (
    CryptoDataLoader, FeatureEngineer, TripleBarrierLabeling,
    MetaLabeling, ModelTrainer, EventFilter
)

def render():
    st.title("æ¨¡å‹è¨“ç·´ (MTF å¤šæ™‚é–“æ¡†æ¶ç‰ˆ)")
    
    st.markdown("""
    ä½¿ç”¨é€²éšæ©Ÿå™¨å­¸ç¿’è¨“ç·´äº¤æ˜“æ¨¡å‹ (MTF Confluence System):
    - **æ¶æ§‹**: 15m é€²å ´èˆ‡å¾®è§€çµæ§‹ + 1h ç’°å¢ƒèˆ‡è¶¨å‹¢éæ¿¾
    - **ç‰¹å¾µ**: åŒ…å« 4 æ¬¾ MTF ç¨å®¶ Alpha ç‰¹å¾µ (MVR, CVD Fractal, VWWA, HTF Trend)
    - **å¹³ç©©æ€§**: å…¨é¢å°æ®ºçµ•å°å€¼ç‰¹å¾µï¼Œåªä½¿ç”¨æ¯”ä¾‹èˆ‡æ¨™æº–åŒ–æŒ‡æ¨™
    """)
    
    with st.expander("âš ï¸ é‡è¦:ç‰¹å¾µå¹³ç©©æ€§èªªæ˜", expanded=False):
        st.markdown("""
        ### ç‚ºä»€éº¼å¿…é ˆç§»é™¤çµ•å°å€¼ç‰¹å¾µ?
        
        **è‡´å‘½å•é¡Œ**:
        - è¨“ç·´æ™‚ BTC = $30,000 â†’ `bb_middle = 30000`
        - å›æ¸¬æ™‚ BTC = $90,000 â†’ `bb_middle = 90000`
        - æ¨¡å‹è¦å‰‡: `if bb_middle > 45000: ...` å®Œå…¨å¤±æ•ˆ!
        
        **å·²å°æ®ºçš„å±éšªç‰¹å¾µ**:
        - âœ… çµ•å°åƒ¹æ ¼: open, high, low, close (åŠå…¶ 1h ç‰ˆæœ¬)
        - âœ… çµ•å° BB: bb_middle, bb_upper, bb_lower (åŠå…¶ 1h ç‰ˆæœ¬)
        - âœ… çµ•å°æˆäº¤é‡: volume, volume_ma_20 (åŠå…¶ 1h ç‰ˆæœ¬)
        - âœ… å ±åƒ¹ç¸½é‡: quote_volume, taker_buy_quote_asset_volume (åŠå…¶ 1h ç‰ˆæœ¬)
        - âœ… API ä¸ç©©å®šæ¬„ä½: trades
        
        **ä¿ç•™çš„å¹³ç©©ç‰¹å¾µ**:
        - âœ“ MTF Alpha: MVR, CVD Fractal, VWWA, HTF Trend Age
        - âœ“ æ¯”ä¾‹ç‰¹å¾µ: bb_width_pct, volume_ratio, taker_buy_ratio
        - âœ“ æ¨™æº–åŒ–: rsi_normalized, cvd_norm_10
        - âœ“ è·é›¢æ¯”: ema_9_dist, ema_21_dist
        - âœ“ å½±ç·šæ¯”: upper_wick_ratio, lower_wick_ratio
        """)
    
    st.markdown("---")
    
    with st.expander("è¨“ç·´é…ç½®", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            loader = CryptoDataLoader()
            symbol = st.selectbox("è¨“ç·´äº¤æ˜“å°", loader.get_available_symbols(), index=10)
            st.info("ç³»çµ±æ¶æ§‹: 15m (é€²å ´èˆ‡å¾®è§€çµæ§‹) + 1h (ç’°å¢ƒèˆ‡è¶¨å‹¢éæ¿¾)")
            
            tp_multiplier = st.number_input("æ­¢ç›ˆå€æ•¸ (ATR)", value=3.0, step=0.5)
            sl_multiplier = st.number_input("æ­¢æå€æ•¸ (ATR)", value=1.0, step=0.25)
        
        with col2:
            max_holding_bars = st.number_input("æœ€å¤§æŒå€‰æ ¹æ•¸ (15m Kç·š)", value=48, step=1, help="48æ ¹ = 12å°æ™‚")
            n_splits = st.number_input("äº¤å‰é©—è­‰æŠ˜æ•¸", value=5, step=1, min_value=3, max_value=10)
            embargo_pct = st.number_input("ç¦æ­¢å€ç™¾åˆ†æ¯”", value=0.01, step=0.01, format="%.3f")
            use_calibration = st.checkbox("å•Ÿç”¨æ©Ÿç‡æ ¡æº–", value=True)
    
    with st.expander("åš´æ ¼äº‹ä»¶éæ¿¾", expanded=True):
        st.markdown("""
        **ä¸‰é‡ç¢ºèª (AND)**: 1)æˆäº¤é‡çˆ†ç™¼ 2)åƒ¹æ ¼çªç ´20æœŸ 3)æ³¢å‹•ç‡çˆ†ç™¼
        """)
        
        use_event_filter = st.checkbox("å•Ÿç”¨åš´æ ¼éæ¿¾", value=True)
        
        col1, col2 = st.columns(2)
        with col1:
            min_volume_ratio = st.number_input("æœ€å°æˆäº¤é‡æ¯”ç‡ (15m)", value=2.0, step=0.1)
            use_strict = st.checkbox("åš´æ ¼æ¨¡å¼ (AND)", value=True)
        with col2:
            min_vsr = st.number_input("æœ€å°æ³¢å‹•ç‡", value=1.0, step=0.1)
            bb_squeeze = st.number_input("BBå£“ç¸®é–€æª»", value=0.5, step=0.1)
            lookback_period = st.number_input("çªç ´å›çœ‹é€±æœŸ (Kç·š)", value=40, step=10)
    
    with st.expander("é€²éšé…ç½®", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            slippage = st.number_input("æ»‘é»", value=0.001, step=0.0001, format="%.4f")
            time_decay_lambda = st.number_input("æ™‚é–“è¡°æ¸›ä¿‚æ•¸", value=2.0, step=0.5)
            quality_alpha = st.number_input("è³ªé‡å¾®èª¿ä¿‚æ•¸", value=0.5, step=0.1,
                                           help="å¾®èª¿ç¯„åœ 1.0-1.5, ä¸å†æ”¾å¤§åŸºç¤æ¬Šé‡")
        with col2:
            use_quality_weight = st.checkbox("å•Ÿç”¨è³ªé‡å¾®èª¿", value=False,
                                            help="é—œé–‰å¾Œæ‰€æœ‰æ¨£æœ¬æ¬Šé‡ç‚º1.0")
            use_class_weight = st.checkbox("ä½¿ç”¨é¡åˆ¥æ¬Šé‡å¹³è¡¡", value=False)
    
    with st.expander("æ¨¡å‹è¶…åƒæ•¸", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            max_depth = st.number_input("æœ€å¤§æ·±åº¦", value=4, min_value=3, max_value=6)
            learning_rate = st.number_input("å­¸ç¿’ç‡", value=0.02, step=0.01, format="%.3f")
            n_estimators = st.number_input("æ¨¹çš„æ•¸é‡", value=300, step=50)
        with col2:
            min_child_weight = st.number_input("æœ€å°å­ç¯€é»æ¬Šé‡", value=5, min_value=3, max_value=10)
            subsample = st.number_input("å­æ¨£æœ¬æ¯”ä¾‹", value=0.7, step=0.1, format="%.2f")
            colsample_bytree = st.number_input("ç‰¹å¾µæ¡æ¨£æ¯”ä¾‹", value=0.6, step=0.1, format="%.2f")
    
    model_name = st.text_input("æ¨¡å‹åç¨±", value=f"{symbol}_MTF_15m_1h_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl")
    
    if st.button("é–‹å§‹è¨“ç·´", type="primary"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("è¼‰å…¥ 15m èˆ‡ 1h æ•¸æ“š...")
            progress_bar.progress(5)
            df_15m = loader.load_klines(symbol, '15m')
            df_1h = loader.load_klines(symbol, '1h')
            
            st.info(f"è¼‰å…¥å®Œæˆ: 15m ({len(df_15m)} ç­†), 1h ({len(df_1h)} ç­†)")
            st.info(f"æ•¸æ“šç¯„åœ: {df_15m['open_time'].min()} è‡³ {df_15m['open_time'].max()}")
            
            status_text.text("å»ºç«‹å–®ä¸€é€±æœŸç‰¹å¾µ...")
            progress_bar.progress(10)
            feature_engineer = FeatureEngineer()
            
            df_15m_features = feature_engineer.build_features(df_15m, include_microstructure=True)
            df_1h_features = feature_engineer.build_features(df_1h, include_microstructure=True)
            
            status_text.text("åˆä½µå¤šæ™‚é–“æ¡†æ¶ (MTF) ç‰¹å¾µ...")
            progress_bar.progress(15)
            
            df_mtf = feature_engineer.merge_and_build_mtf_features(df_15m_features, df_1h_features)
            st.success(f"MTF ç‰¹å¾µåˆä½µå®Œæˆ! æœ€çµ‚æ•¸æ“šå½¢ç‹€: {df_mtf.shape}")
            
            df_features = df_mtf
            
            if use_event_filter:
                status_text.text("æ‡‰ç”¨åš´æ ¼äº‹ä»¶éæ¿¾...")
                progress_bar.progress(20)
                
                event_filter = EventFilter(
                    use_strict_mode=use_strict,
                    min_volume_ratio=min_volume_ratio,
                    min_vsr=min_vsr,
                    bb_squeeze_threshold=bb_squeeze,
                    lookback_period=int(lookback_period)
                )
                
                df_filtered = event_filter.filter_events(df_features)
                filter_ratio = len(df_filtered) / len(df_features)
                st.info(f"äº‹ä»¶éæ¿¾: {len(df_features)} â†’ {len(df_filtered)} ({100*filter_ratio:.1f}%)")
                
                if filter_ratio > 0.25:
                    st.warning(f"éæ¿¾å¾Œä»ä¿ç•™ {filter_ratio*100:.0f}% (å»ºè­°èª¿æ•´åƒæ•¸ä»¥ä½æ–¼ 25%)")
                
                df_features = df_filtered
            
            status_text.text("æ‡‰ç”¨ä¸‰é‡å±éšœæ¨™è¨˜...")
            progress_bar.progress(25)
            
            labeler = TripleBarrierLabeling(
                tp_multiplier=tp_multiplier,
                sl_multiplier=sl_multiplier,
                max_holding_bars=int(max_holding_bars),
                slippage=slippage,
                time_decay_lambda=time_decay_lambda,
                quality_weight_alpha=quality_alpha,
                use_quality_weight=use_quality_weight
            )
            df_labeled = labeler.apply_triple_barrier(df_features)
            
            positive_count = (df_labeled['label'] == 1).sum()
            negative_count = (df_labeled['label'] == 0).sum()
            positive_pct = positive_count / len(df_labeled) * 100
            
            avg_weight_pos = df_labeled[df_labeled['label'] == 1]['sample_weight'].mean()
            avg_weight_neg = df_labeled[df_labeled['label'] == 0]['sample_weight'].mean()
            
            st.info(f"æ¨™ç±¤åˆ†å¸ƒ: {positive_pct:.1f}% æ­£æ¨£æœ¬ ({positive_count} å‹, {negative_count} è² )")
            st.info(f"æ¨£æœ¬æ¬Šé‡ - æ­£é¡: {avg_weight_pos:.2f}, è² é¡: {avg_weight_neg:.2f}")
            
            status_text.text("æº–å‚™è¨“ç·´æ•¸æ“š (ç‰¹å¾µå¤§æƒé™¤)...")
            progress_bar.progress(35)
            
            st.warning("âš ï¸ ç‰¹å¾µå¤§æƒé™¤:ç§»é™¤çµ•å°å€¼èˆ‡ API ä¸ç©©å®šç‰¹å¾µ")
            
            base_cols = [
                'open_time', 'close_time', 'htf_close_time',
                'label', 'label_return', 'hit_time', 'exit_type', 'sample_weight', 'mae_ratio',
                'exit_price', 'exit_bars', 'return', 'ignore'
            ]
            
            # ===== [ä¿®æ­£] å°æ®º taker_buy_quote_asset_volume (èª¤ç”¨éå¹³ç¨©ç‰¹å¾µ) =====
            forbidden_features = [
                # çµ•å°åƒ¹æ ¼
                'open', 'high', 'low', 'close',
                'bb_middle', 'bb_upper', 'bb_lower', 'bb_std',
                
                # çµ•å°æˆäº¤é‡
                'volume', 'volume_ma_20',
                'taker_buy_base_asset_volume',
                
                # å ±åƒ¹ç¸½é‡ (éå¹³ç¨©ç‰¹å¾µï¼Œå› åƒ¹æ ¼æ³¢å‹•è€Œè®Šå‹•)
                'quote_asset_volume', 'quote_volume',
                'taker_buy_quote_asset_volume',  # <- è‡´å‘½æ´©æ¼
                
                # API ä¸ç©©å®šæ¬„ä½
                'number_of_trades', 'trades',
                'open_interest', 'atr',
                
                # 1h çµ•å°ç‰¹å¾µ
                'open_1h', 'high_1h', 'low_1h', 'close_1h',
                'bb_middle_1h', 'bb_upper_1h', 'bb_lower_1h', 'bb_std_1h',
                'volume_1h', 'volume_ma_20_1h',
                'taker_buy_base_asset_volume_1h',
                'quote_asset_volume_1h', 'quote_volume_1h',
                'taker_buy_quote_asset_volume_1h',  # <- è‡´å‘½æ´©æ¼ (1h ç‰ˆæœ¬)
                'number_of_trades_1h', 'trades_1h', 
                'open_interest_1h', 'atr_1h'
            ]
            
            exclude_all = base_cols + forbidden_features
            
            feature_cols = [col for col in df_labeled.columns if col not in exclude_all]
            feature_cols = [col for col in feature_cols 
                          if df_labeled[col].dtype in ['int64', 'float64', 'bool', 'int32', 'float32']]
            
            removed_features = [col for col in df_labeled.columns if col in forbidden_features]
            if len(removed_features) > 0:
                st.info(f"âœ… ç§»é™¤ {len(removed_features)} å€‹éå¹³ç¨©ç‰¹å¾µ (å«1hç‰ˆæœ¬)")
            
            X = df_labeled[feature_cols].copy()
            y = df_labeled['label'].copy()
            sample_weights = df_labeled['sample_weight'].values
            
            X = X.fillna(0)
            X = X.replace([np.inf, -np.inf], 0)
            
            for col in X.select_dtypes(include=['bool']).columns:
                X[col] = X[col].astype(int)
            
            st.info(f"è¨“ç·´æ•¸æ“š: {len(X)} æ¨£æœ¬, {len(feature_cols)} ç‰¹å¾µ")
            
            with st.expander("ä¿ç•™çš„å¹³ç¨©ç‰¹å¾µ (é»æ“ŠæŸ¥çœ‹)", expanded=False):
                st.code('\n'.join(feature_cols))
            
            status_text.text("Purged K-Fold è¨“ç·´...")
            progress_bar.progress(50)
            
            trainer = ModelTrainer(use_calibration=use_calibration)
            
            scale_pos_weight = negative_count / positive_count if use_class_weight and positive_count > 0 else 1.0
            if scale_pos_weight != 1.0:
                st.warning(f"é¡åˆ¥æ¬Šé‡: {scale_pos_weight:.2f}")
            else:
                st.info("é¡åˆ¥æ¬Šé‡: 1.0")
            
            params = {
                'max_depth': int(max_depth),
                'learning_rate': float(learning_rate),
                'n_estimators': int(n_estimators),
                'min_child_weight': int(min_child_weight),
                'subsample': float(subsample),
                'colsample_bytree': float(colsample_bytree),
                'scale_pos_weight': scale_pos_weight,
                'reg_alpha': 0.1,
                'reg_lambda': 1.0
            }
            
            cv_metrics = trainer.train_with_purged_kfold(
                X, y,
                sample_weights=sample_weights,
                n_splits=int(n_splits),
                embargo_pct=float(embargo_pct),
                params=params
            )
            
            progress_bar.progress(90)
            status_text.text("ä¿å­˜æ¨¡å‹...")
            trainer.save_model(model_name)
            
            progress_bar.progress(100)
            status_text.text("è¨“ç·´å®Œæˆ")
            
            st.success(f"æ¨¡å‹å·²ä¿å­˜: {model_name}")
            
            st.markdown("### äº¤å‰é©—è­‰çµæœ")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æº–ç¢ºç‡", f"{cv_metrics.get('cv_val_accuracy', 0):.4f} Â± {cv_metrics.get('cv_val_accuracy_std', 0):.4f}")
            with col2:
                auc_val = cv_metrics.get('cv_val_auc', 0)
                auc_delta = auc_val - 0.5
                st.metric("AUC", f"{auc_val:.4f}",
                         delta=f"+{auc_delta:.4f}")
            with col3:
                prec = cv_metrics.get('cv_val_precision', 0)
                st.metric("ç²¾ç¢ºç‡", f"{prec:.4f}")
            with col4:
                recall = cv_metrics.get('cv_val_recall', 0)
                st.metric("å¬å›ç‡", f"{recall:.4f}")
            
            if prec > 0 and recall > 0:
                ev = (prec * tp_multiplier) - ((1 - prec) * sl_multiplier)
                st.info(f"æœŸæœ›å€¼ (EV): {ev:.3f}R ({'positive' if ev > 0 else 'negative'})")
                if ev > 0.2:
                    st.success(f"æ¨¡å‹å„ªç§€! AUC={auc_val:.3f}, EV={ev:.2f}R")
                elif ev > 0:
                    st.info(f"æ¨¡å‹åˆæ ¼! EV={ev:.2f}R > 0")
            
            if auc_val < 0.55:
                st.error(f"AUC {auc_val:.3f} < 0.55")
            
            if recall > 0.70 and prec < 0.40:
                st.warning("å¬å›ç‡éé«˜,æ¨¡å‹æ¿¾ç™¼ä¿¡è™Ÿ")
            
            st.markdown("### ç‰¹å¾µé‡è¦æ€§ (å‰ 20 å)")
            feature_importance = trainer.get_feature_importance()
            
            mtf_features = ['mvr', 'cvd_fractal', 'vwwa_buy', 'vwwa_sell', 'htf_trend_age_norm']
            
            top_15 = feature_importance.head(15)['feature'].tolist()
            mtf_in_top = [f for f in mtf_features if f in top_15]
            
            if len(mtf_in_top) > 0:
                st.success(f"âœ… {len(mtf_in_top)} å€‹ MTF Alpha ç‰¹å¾µåœ¨ Top 15: {', '.join(mtf_in_top)}")
            else:
                st.info("MTF ç‰¹å¾µæœªé€²å…¥å‰ 15 åï¼Œè«‹æª¢æŸ¥æ•¸æ“šé‡æˆ–åƒæ•¸")
                
            st.dataframe(feature_importance.head(20), use_container_width=True)
            
            # ===== [æ–°å¢] è©³ç´°è¨“ç·´å ±å‘Š (å¯è¤‡è£½çµ¦ Gemini) =====
            st.markdown("---")
            st.markdown("### ğŸ“‹ è©³ç´°è¨“ç·´å ±å‘Š (å¯è¤‡è£½çµ¦ Gemini æŸ¥çœ‹)")
            
            report = f"""
# MTF å¤šæ™‚é–“æ¡†æ¶äº¤æ˜“æ¨¡å‹è¨“ç·´å ±å‘Š

## æ¨¡å‹é…ç½®
- **äº¤æ˜“å°**: {symbol}
- **æ™‚é–“æ¡†æ¶**: 15m (é€²å ´) + 1h (ç’°å¢ƒéæ¿¾)
- **æ¨¡å‹æª”æ¡ˆ**: {model_name}
- **è¨“ç·´æ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ•¸æ“šæ¦‚è¦
- **15m æ•¸æ“š**: {len(df_15m)} ç­†
- **1h æ•¸æ“š**: {len(df_1h)} ç­†
- **MTF åˆä½µå¾Œ**: {df_mtf.shape[0]} ç­†, {df_mtf.shape[1]} æ¬„
- **äº‹ä»¶éæ¿¾å¾Œ**: {len(df_features)} ç­† ({100*len(df_features)/len(df_mtf):.1f}%)
- **æ•¸æ“šç¯„åœ**: {df_15m['open_time'].min()} è‡³ {df_15m['open_time'].max()}

## æ¨™ç±¤é…ç½®
- **æ­¢ç›ˆ (TP)**: {tp_multiplier:.1f} ATR
- **æ­¢æ (SL)**: {sl_multiplier:.1f} ATR
- **æœ€å¤§æŒå€‰**: {max_holding_bars} æ ¹ 15m Kç·š ({max_holding_bars/4:.1f} å°æ™‚)
- **æ¨£æœ¬æ¬Šé‡**: {'Enabled' if use_quality_weight else 'Disabled'}
- **é¡åˆ¥æ¬Šé‡**: {scale_pos_weight:.2f}

## æ¨™ç±¤åˆ†å¸ƒ
- **æ­£æ¨£æœ¬ (å‹)**: {positive_count} ({positive_pct:.1f}%)
- **è² æ¨£æœ¬ (è² )**: {negative_count} ({100-positive_pct:.1f}%)
- **å¹³å‡æ¬Šé‡ (æ­£)**: {avg_weight_pos:.2f}
- **å¹³å‡æ¬Šé‡ (è² )**: {avg_weight_neg:.2f}

## ç‰¹å¾µå·¥ç¨‹
- **åŸå§‹ç‰¹å¾µæ•¸**: {len(df_labeled.columns)} å€‹
- **ç§»é™¤éå¹³ç¨©ç‰¹å¾µ**: {len(removed_features)} å€‹
- **æœ€çµ‚ä¿ç•™ç‰¹å¾µ**: {len(feature_cols)} å€‹
- **MTF Alpha ç‰¹å¾µ**: {', '.join(mtf_features)}

## äº¤å‰é©—è­‰çµæœ (Purged K-Fold, {n_splits} Folds)
- **æº–ç¢ºç‡**: {cv_metrics.get('cv_val_accuracy', 0):.4f} Â± {cv_metrics.get('cv_val_accuracy_std', 0):.4f}
- **AUC**: {auc_val:.4f} (delta: +{auc_delta:.4f})
- **ç²¾ç¢ºç‡ (Precision)**: {prec:.4f}
- **å¬å›ç‡ (Recall)**: {recall:.4f}
- **æœŸæœ›å€¼ (EV)**: {ev:.3f}R

## æ¨¡å‹è¶…åƒæ•¸
- **max_depth**: {max_depth}
- **learning_rate**: {learning_rate}
- **n_estimators**: {n_estimators}
- **min_child_weight**: {min_child_weight}
- **subsample**: {subsample}
- **colsample_bytree**: {colsample_bytree}

## ç‰¹å¾µé‡è¦æ€§ Top 20
{feature_importance.head(20).to_string()}

## MTF Alpha ç‰¹å¾µåœ¨ Top 15
{', '.join(mtf_in_top) if len(mtf_in_top) > 0 else 'None'}

## ä¿ç•™çš„å¹³ç¨©ç‰¹å¾µåˆ—è¡¨
{chr(10).join(feature_cols)}
"""
            
            st.text_area("å ±å‘Šå…§å®¹ (é»æ“Šå³ä¸Šè§’è¤‡è£½)", report, height=400)
            
            st.markdown("### ä¸‹ä¸€æ­¥")
            if auc_val >= 0.58:
                st.success("âœ… æ¨¡å‹è¨“ç·´æˆåŠŸ!ç¾åœ¨å¯ä»¥é€²è¡Œ **OOS ç›²æ¸¬**")
                st.info("""
                **ç¬¬äºŒéšæ®µæª¢æŸ¥æ¸…å–®**:
                1. å‰å¾€ **å›æ¸¬åˆ†æ**
                2. é¸æ“‡ MTF è¨“ç·´å‡ºçš„æ¨¡å‹
                3. æ•¸æ“šä¾†æº: **Binance API (æœ€æ–° 90 å¤©)**
                4. è¨­å®šé¢¨æ§: æ©Ÿç‡é–€æª» 0.55, å–®ç­†é¢¨éšª 2%, TP 3.0 / SL 1.0
                5. å•Ÿç”¨åš´æ ¼äº‹ä»¶éæ¿¾ (èˆ‡è¨“ç·´æ™‚å®Œå…¨ä¸€è‡´)
                """)
            
        except Exception as e:
            st.error(f"è¨“ç·´å¤±æ•—: {str(e)}")
            import traceback
            st.code(traceback.format_exc())